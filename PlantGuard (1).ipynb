{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fc7k_L8xwdMP"
      },
      "outputs": [],
      "source": [
        "# Installing necessary libraries\n",
        "!pip install tensorflow keras opencv-python\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n"
      ],
      "metadata": {
        "id": "sHAYymPnwxF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "84V9lr8x2NYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Path to the ZIP file in your Drive\n",
        "zip_path = '/content/drive/MyDrive/Colab Notebooks/Plant.zip'\n",
        "\n",
        "# Path to extract files\n",
        "extract_path = '/content/plant_dataset'\n",
        "\n",
        "# Unzip the dataset\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "# Check if the data is extracted properly\n",
        "print(\"Extracted folders:\", os.listdir(extract_path))\n"
      ],
      "metadata": {
        "id": "aQlv55aK2osU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List the contents of the extracted folder\n",
        "for folder in os.listdir(extract_path):\n",
        "    folder_path = os.path.join(extract_path, folder)\n",
        "    if os.path.isdir(folder_path):\n",
        "        print(f\"Folder: {folder}\")\n",
        "        print(\"Files:\", os.listdir(folder_path))\n"
      ],
      "metadata": {
        "id": "DYL-NW1L34xZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check contents of a specific folder (e.g., 'Apple___scab')\n",
        "sample_folder_path = os.path.join(extract_path, 'data', 'Apple___scab')\n",
        "print(\"Sample files:\", os.listdir(sample_folder_path))\n"
      ],
      "metadata": {
        "id": "2RsYwWQz4dEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Set the dataset path\n",
        "extract_path = '/content/plant_dataset'\n",
        "image_size = (128, 128)\n",
        "batch_size = 32\n",
        "\n",
        "# Define data generators\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    directory=os.path.join(extract_path, 'data'),\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    directory=os.path.join(extract_path, 'data'),\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# Load the MobileNetV2 model (pretrained on ImageNet)\n",
        "base_model = MobileNetV2(input_shape=(128, 128, 3), include_top=False, weights='imagenet')\n",
        "base_model.trainable = False  # Freeze base model\n",
        "\n",
        "# Add custom classification layers\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "outputs = Dense(len(train_generator.class_indices), activation='softmax')(x)\n",
        "\n",
        "# Combine into a model\n",
        "model = Model(inputs=base_model.input, outputs=outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Add early stopping\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    epochs=5,  # You can increase this after testing\n",
        "    validation_data=validation_generator,\n",
        "    callbacks=[early_stop]\n",
        ")\n"
      ],
      "metadata": {
        "id": "RalqAfyKvAen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save entire model in HDF5 format\n",
        "model.save('plant_disease_model.h5')\n",
        "print(\"Model saved as plant_disease_model.h5\")\n"
      ],
      "metadata": {
        "id": "_-HGaksNvDnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/content/plant_disease_model.h5')\n"
      ],
      "metadata": {
        "id": "1RihEwh3XyG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=3,\n",
        "    validation_data=validation_generator,\n",
        "    steps_per_epoch=100,\n",
        "    validation_steps=20,\n",
        "    callbacks=[early_stop]\n",
        ")\n"
      ],
      "metadata": {
        "id": "ZaCTOBmxEHv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Accuracy\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Loss\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "euCc5vB8KkiS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "folder_path = '/content/plant_dataset/data/Tomato___healthy'\n",
        "print(\"Files:\", os.listdir(folder_path)[:5])  # print first 5 file names\n"
      ],
      "metadata": {
        "id": "bELA3fsCM607"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "# Use a valid image from the folder\n",
        "img_path = '/content/plant_dataset/data/Tomato___healthy/96258.jpg'\n",
        "\n",
        "# Load and preprocess the image\n",
        "img = image.load_img(img_path, target_size=(128, 128))\n",
        "img_array = image.img_to_array(img) / 255.0\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "# Predict using the trained model\n",
        "prediction = model.predict(img_array)\n",
        "predicted_class = np.argmax(prediction)\n",
        "\n",
        "# Get class name\n",
        "class_names = list(train_generator.class_indices.keys())\n",
        "print(\"Predicted class:\", class_names[predicted_class])\n"
      ],
      "metadata": {
        "id": "BJluidJ5NLow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit\n"
      ],
      "metadata": {
        "id": "N95JlkVDN3ho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "\n",
        "# Load the trained model\n",
        "model = load_model('plant_disease_model.h5')\n",
        "\n",
        "# Define a function for prediction\n",
        "def predict_image(image_path):\n",
        "    img = image.load_img(image_path, target_size=(128, 128))\n",
        "    img_array = image.img_to_array(img) / 255.0\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    prediction = model.predict(img_array)\n",
        "    predicted_class = np.argmax(prediction)\n",
        "    return predicted_class\n",
        "\n",
        "# Set up Streamlit interface\n",
        "st.title('Plant Disease Prediction App')\n",
        "uploaded_file = st.file_uploader(\"Choose an image...\", type=[\"jpg\", \"png\", \"jpeg\"])\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    # Save the uploaded image\n",
        "    with open(\"uploaded_image.jpg\", \"wb\") as f:\n",
        "        f.write(uploaded_file.getbuffer())\n",
        "\n",
        "    # Predict on the uploaded image\n",
        "    result = predict_image(\"uploaded_image.jpg\")\n",
        "    st.image(\"uploaded_image.jpg\", caption='Uploaded Image', use_column_width=True)\n",
        "    st.write(f\"Predicted Class: {result}\")\n"
      ],
      "metadata": {
        "id": "CpiqmtFcN98D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok\n"
      ],
      "metadata": {
        "id": "GlY6XT2kOCjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "# Load model\n",
        "model = load_model('plant_disease_model.h5')\n",
        "\n",
        "st.title('Plant Disease Detection')\n",
        "st.write('Upload an image of the plant leaf to check for disease.')\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Choose a plant leaf image...\", type=[\"jpg\", \"png\", \"jpeg\"])\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    img = image.load_img(uploaded_file, target_size=(224, 224))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array = img_array / 255.0\n",
        "\n",
        "    prediction = model.predict(img_array)\n",
        "    st.image(uploaded_file, caption=\"Uploaded Image\", use_column_width=True)\n",
        "\n",
        "    if prediction[0] > 0.5:  # Example threshold; adjust as needed\n",
        "        st.write(\"The plant is infected!\")\n",
        "    else:\n",
        "        st.write(\"The plant is healthy!\")\n"
      ],
      "metadata": {
        "id": "0CA20bYyQr9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit pyngrok --quiet\n"
      ],
      "metadata": {
        "id": "PfOVTdLeSEnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "\n",
        "st.title(\"üåø Plant Disease Detection\")\n",
        "st.write(\"Upload a leaf image to check for disease (Demo)\")\n"
      ],
      "metadata": {
        "id": "c2IquVViSSoj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "\n",
        "# Load the trained model\n",
        "model = load_model(\"plant_disease_model.h5\")\n",
        "\n",
        "# Class labels (update based on your training data)\n",
        "class_labels = [\n",
        "    \"Apple Scab\", \"Apple Black Rot\", \"Apple Cedar Rust\", \"Apple Healthy\",\n",
        "    \"Corn Gray Leaf Spot\", \"Corn Common Rust\", \"Corn Northern Leaf Blight\", \"Corn Healthy\",\n",
        "    \"Grape Black Rot\", \"Grape Esca\", \"Grape Leaf Blight\", \"Grape Healthy\"\n",
        "]\n",
        "\n",
        "st.title(\"üåø Plant Disease Detection\")\n",
        "st.write(\"Upload a leaf image to identify the disease.\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Choose a leaf image\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    image = Image.open(uploaded_file).resize((224, 224))\n",
        "    st.image(image, caption=\"Uploaded Leaf Image\", use_column_width=True)\n",
        "\n",
        "    # Preprocess the image\n",
        "    img_array = img_to_array(image)\n",
        "    img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = model.predict(img_array)\n",
        "    predicted_class = class_labels[np.argmax(prediction)]\n",
        "\n",
        "    st.success(f\"üîç Predicted Disease: **{predicted_class}**\")\n"
      ],
      "metadata": {
        "id": "YY2dKszSZmjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "PtlLIdKhaZwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok config add-authtoken 2x1qcQnqCnJheTfWi6ctlAoW0d2_sjjqG2WbEYiFxZ3NWBQd\n"
      ],
      "metadata": {
        "id": "TS4wCbS-azMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (Optional) Kill old tunnels\n",
        "from pyngrok import ngrok\n",
        "ngrok.kill()\n",
        "\n",
        "# Run Streamlit app in background\n",
        "!streamlit run app.py --server.port 8501 &\n",
        "\n",
        "# Start ngrok tunnel\n",
        "public_url = ngrok.connect(addr=8501, proto=\"http\")\n",
        "print(\"üåê Public URL:\", public_url)\n"
      ],
      "metadata": {
        "id": "M-B9pxrybElb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}